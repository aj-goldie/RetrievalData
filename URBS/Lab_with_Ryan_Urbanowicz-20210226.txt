 Hello and welcome to lecture 11 of Foundations of Artificial Intelligence. Today we're going to learn about one other form of knowledge representation in particular that of rules. And then this will segue into an introduction to expert systems. In our last lecture, we covered semantic webs. We learned about trees as another form of knowledge representation. And also learned about decision trees as an induction method for machine learning. And lastly, we gave a tour of other machine learning algorithms that are based on decision trees. In particular, we learned a little about ensembles, bagging, and boosting. Here's the outline for today's lecture. Again, we're going to cover rules, expert systems, including what they are, why they're useful, and when they're a relevant choice to either build or use. Then as a precursor to our next lecture, we'll give the brief introduction to rule-based systems, which is a particular type of expert system. We begin by looking at rules as another form of knowledge representation. We've seen this slide in an earlier lecture that laid out the key knowledge representations that we're going to focus on in this course. The first were logical representations. Later we learned about semantic networks and frames. And finally, today we're going to talk about rules. Rules are pretty straightforward. They're typically given as if-then expressions. You have if, one or more conditions, then some conclusion. They can similarly be represented as condition action expressions. So again, if one or more conditions, then do some action. Rules themselves are effectively propositional or first order logic implications. Here's a really simple example of a rule. If the traffic light is red and you have stopped, then a right turn is okay. A quick biomedical example. If patient has high levels of the enzyme ferritin in their blood, and patient has the cyst-282 thirosinase mutation in HFE gene, then conclude patient has hemochromatosis. The first two conditions given the if statements are separate propositions, which if true indicate that our consequence or conclusion is true. The term condition is also known as the premise, the antecedent, or you can think of them as independent variables. The conclusion can also be referred to as the action, the result, the consequent, the goal, the outcome, or you can think of it as a dependent variable. Let's dig a little more into the rules antecedent or its condition. This is the if part of the rule, and the antecedent represents a series of tests to be conducted, not unlike the tests at each node of a decision tree. There's some natural links between rules and trees that we will identify for their later, but it's first worth noting that in terms of expert systems, rules are a popular alternative to decision trees. These tests that make up the antecedents are usually logically and together. This is similar to the definite clauses from logic used for chaining inference. However, in certain circumstances, rules can have different logical expressions in them. Now let's take a closer look at the conclusion or the consequence of the rule. This is the then portion, and the consequent can either be a single conclusion or a set of conclusions, similarly it can be an action or a set of actions. Additionally, for each conclusion or action, the consequent can have a probability distribution, assigned by the rule specifying the support or certainty for that given consequent. We'll get into this further when we get into reasoning with uncertainty later on, in a later lecture. It's good to note up front that if you have multiple rules whose antecedents are satisfied, then you can end up with a situation where you have conflicts in terms of the consequence being a certain So, like from semantic networks, we can have situations where we need to deal with conflict resolution. Consequence can be used in a number of ways. One is to express a relationship. In other words, if the fuel tank is empty, then the car is dead. They could also be utilized to make recommendations. So, for example, if the season is autumn and the sky is cloudy and the forecast is drizzle, then the advice or recommendation is to take an umbrella. Consequence can also represent directives, or you can think of them again as actions. So, in this case, if the car is dead and the fuel tank is empty, then the action is refueled a car. Further, consequence can be used to set up some higher level strategy. As a rough example of this, imagine the scenario where we have if the car is dead, then the action is checked the fuel tank. Further, add the fact that step one is complete. Then another rule in the knowledge base might say if step one is complete and the fuel tank is full, then the action is checked the battery. And at this point, the fact step two is complete will also be added to the knowledge base. And lastly, consequence can be used as heuristics to represent some kind of prediction model, either for classification or for regression. As an example, we have if the spill is liquid and the spill pH is under six, and the spill smell is vinegar, then the spill material is acetic acid. In this case, we have some evidence that is being used to support some prediction as to what the outcome material is. Depending on the certainty of the facts, as well as the certainty of the association between the facts and the outcome, this prediction in here at the bottom in the consequence can have some certainty associated with it. Going from 100% confidence to something much lower. Here's a summary of the basic information about rules for your reference in the future. It includes information about names that we just covered, the nature of these two parts of rules, where conditions are similar to declarative knowledge, and consequence are resolutions similar to procedural knowledge. In terms of the size of the parts, the antecedents can have many ifs linked by ands usually. And typically, the consequence usually have only one conclusion, but this is not always the case. And then we have the two most common kinds of connectors found in rules and/or/or, where for ands all conditions must be true for the conclusion to be true. And obviously, if we have ores linking them, if any of those conditions is true, then the conclusion is true. We can also add a variety of conditional relations to rules. Rules can compare attribute values to a constant, for example, temperature less than 45 degrees, and these would be called propositional rules, which have the same expressive power as in propositional logic. For example, if credit rating is high, and salary is no more than 30,000 pounds, or assets are more than 75,000 pounds, and pay history is not poor, then approve the loan of 10,000 pounds, and list the loan in category B. This is an example of rules that have variables that get filled in and compared using conditional relations in order to determine the truthfulness of this rule expression. But what happens when we want to look at a relationship between multiple attributes? These can't be expressed with simple propositional rules and a more expressive representation is required, similar to what we looked at as we went from propositional logic to first order logic. Fortunately, we can do this pretty simply in rules, for example, if width is greater than height, then consequent is lying, or if height is greater than width, then consequent is standing. This is a simple example of rules that might be trying to determine how a person is positioned. This kind of rule representation generalizes better to new data, but unfortunately searching for relations between attributes can be computationally expensive. One simple solution is to add extra attributes via feature construction. For instance, to add an attribute that is already checked whether width is greater than height and have a true or false value. However, you can also use variables and multiple relations similar to what we saw in first order logic. For example, if height and width of xhw and h is greater than w, then standing. Here, this expression indicates the height and width of person x. It's worth noting at this point that there are also some other less common rule forms that you might encounter. For example, sometimes rules can be presented with the conclusion first given as conclusion if condition. So in other words, your chance of being audited is high if your income is high. You might also see rules that include the else expression. So for example, if your income is high, or your deductions are unusual, then your chance of being audited is high, or else your chance of being audited is low. This has a similar structure to if/then else loops that come from computer programming. You can also have situations where the action or consequent of a rule will actually trigger other rules or multiple actions. So for example, you could have a rule that triggers then, approve the loan, and refer to an agent. In this case, two actions are presented. Now let's start to think of rules as a collective group that form a knowledge base from which we can work from. First off, let's consider that there are two ways of executing a rule set. First, you can have an ordered set of rules. This is also known as a decision list. In this situation, the order of rules is important for how it's interpreted. Differently, we can also have unordered rule sets. Here, rules can overlap and lead to different conclusions for the same instance. In other words, introduce conflicts. However, there are some benefits to having an unordered versus an ordered rule set. Another thing you can do with a knowledge base of rules is to rely on default rules. This tends to be common when using ordered rule sets. Basically here, the idea is that you create rules for other outcomes, and if they're not satisfied, then a default rule with a default action or conclusion is triggered. Here's an example where a default rule is used. In this case, we have two rules, the second being a default rule that triggers whenever X is empty, or no other rules have triggered, giving us a consequent to work with. Let's look a little further at this idea of default rules from the context of problems where we have a Boolean class or Boolean outcome. So the assumption here is that if an instance doesn't belong to class, yes, then by default, it belongs to class, no. What's nice when we have this situation is that we only have to implement rules that indicate when we have a situation where a class is yes, and then just rely on the default rule for any situation where the class is no. In this example, our two classes of interest are class A and B, and so we've only provided rules that indicate one more part of class A and otherwise the default rule of class B kicks on. In this situation, the order of the rules is an important, and we don't have any conflicts. Additionally, this set of rules is written as a disjunctive normal form. Specifically, we have two rules, both with antecedents using and, but either of these rules either or can be true in order to decide that we are of class A. Some uses of rules also allow exceptions. Let's take a look at an example using the Iris data set to get a better idea of how we might use exceptions. So here we have if Petal length is greater than 2.45, and Petal length is less than 4.45, then the Iris class is Iris versatileer. Let's assume at this point all the training instances we've looked at backs this situation up. However, maybe another instance comes along that isn't part of class Iris versatileer. Because the Petal length here is 2.6, which would have fallen within this range, we could now come up with an exception to the above rule to make it accurate in this new case. Here's the modified rule with the exception. We've added the phrase except if Petal width is less than 1.0, then classification is Iris Satosa. Here the presumption is that none of the other instances that were correctly classified here by this rule meet the conditions of this exception. This can help us to deal with special cases in the context of rule-based systems. In practice exceptions can get pretty unruly. Here's a more complicated example where a number of exceptions are used. In this example we're using the default rule kind of in reverse. We start with the default of Iris Satosa and then indicate exception conditions. When we want to conclude a different class of Iris. In this case Iris versatileer and Iris virginisa. The advantage of building rule systems using exceptions is that rules can be updated incrementally. In other words it can be easy to incorporate new data or to incorporate new domain knowledge. In terms of interpretability people often think in terms of exceptions. Further each conclusion can be considered just in the context of the rules and exceptions that lead to it. This locality property can be important for understanding and interpreting larger rule sets. What we'll call normal rule sets don't offer the same level of transparency in terms of interpreting the rule base. So while using exceptions and rules can be beneficial to interpretability they can also lead to extreme overfitting when you're developing a rule set. And they might require constant updates as new instances are introduced in the future. So at the end of the day this might not be the best approach in particularly noisy or complex problem spaces. Let's take a moment to look at the big picture of how a normal rule base might be set up and interpreted. Each rule in a knowledge base represents an autonomous chunk of expertise. Each individual rule is conceptually linked through or expressions. When these rules are combined and fed into what's called an inference engine the set of rules behaves synergistically being utilized collectively to make decisions and choose new actions. The use of rules can be viewed as a simulation of the cognitive behavior of human experts. Or otherwise put rules represent a model of actual human behavior. As such they're a predominantly used technique to formulate knowledge in expert systems. And furthermore they're often used in conjunction with frames in the construction of expert systems. We'll get the taste of expert systems at the end of this lecture but we'll dive into the much further in our next lecture. Now that we know the basics of what rules are and how they can be represented let's take another big picture look at how they can be applied to make inferences. In terms of the problems we might be trying to address there are in general two principal types of tasks that imply the use of one of either two control regimes. The first control regime is forward chaining. This is a data-driven approach that we learned a little bit about in logic. Here we start with facts and determine applicable rules and then apply one. There's also backwards chaining which we learned a little bit about in logic which is goal oriented. Here we look for rules which decompose the goal. And then we try to solve secondary subsequent goals until we've proven our original goal. You might initially wonder whether one of these control regimes is better than the other. But the answer to that question really depends on the application and the circumstances. As such both are useful approaches that will want to keep in mind. An important part of using rules to make inferences is the process of rule matching. Matching is all about determining the applicable knowledge of the given situation. In other words based on the knowledge at hand which rules are relevant to look at further. Rules become activated or triggered based on the type of inference or chaining being used. In forward chaining we're trying to match rule and to sedence to the fact base that we have in hand. Whilst in backwards chaining we're trying to match rule consequence to facts and the rule base. However it's this process of matching that can be the most computationally expensive step. Further matching often yields more than one applicable rule that needs to be considered. And in those cases it will be put on an agenda of rules to be looked at in sequence. When multiple rules are applicable these rule instances are said to be in conflict. And we need to use conflict. And we need to use conflict resolution to pick one to fire. Firing is a term used in forward chaining to describe the execution of consequence of an applicable rule instance. In other words if the antecedents of a rule are satisfied then the consequent is added as a new fact through firing. It's also during the matching process that variables and rules acquire values like instantiation for the same situation. So what are the advantages of rules as a representation on a whole? Well first they're simple and easy to understand. And naturally correspond to the way people often think of knowledge. Furthermore they're very expressive. Another advantage is that rules are straightforward to implement in computers. And they allow for the modularization of knowledge. So an engineer of the system can just focus on the validity of individual rules one at a time more than having to worry about a giant conglow or if then else loops or some other more complex type of model. So ultimately rule based systems are also easier to write and debug compared to some other representations. Another nice thing is that there are some formal foundations with respect to inference for example for some of the variance of rule based systems. But not all of them. The more creative you get in putting together a rule based the farther you stray from a formal system that allows you to make reliable inferences. Now let's review some of the disadvantages of rules as a representation. For one simple implementations of rules are often very inefficient. In other words we can modularize our problem too much to make our lives easier in putting together the system. But when it comes to putting it into action that same system might be computationally more expensive than it needs to be to go through the holes searching, matching, and inference process. Also some types of knowledge are not easily expressed as rules. Further a large set of rules can become difficult to understand as well as to maintain. Rule based systems can also be memory intensive as well as computationally expensive. And at the end of the day they can still be difficult to debug. Since we might have to consider the nuances of how rules work together ultimately to make inferences. Rather than just being able to focus on the validity of individual rules one at a time. In other words when rules start to have important interactions between them that can influence the validity of the implications that we're making through the system as a whole. Now that we've learned about rules let's go back to our discussion of decision trees and tie the two together. First off any decision tree can be linearized into what are called decision rules. You can create a decision rule from every unique path from the root of the tree to a given leaf. So for example is it raining? Yes, is it windy? Yes, is it extremely windy? Yes, stay at home. Here the leaf node would be the outcome of that rule describing this entire path up through the tree. As we've seen rules are if then expressions. Here are some examples of decision rules who would get by linearizing this example tree. So for instance if not raining then don't bring anything would represent this part of the tree. If is raining and not windy then use an umbrella would represent this part of the tree. If is raining and is windy and not extremely windy then where a rain jacket would represent this part of the tree. Converting from trees to rules is extremely easy. Again you just get one rule for each leaf in the tree. One nice thing about the rules that you get from a tree is that it won't matter what order they're executed in. However the resulting rule set that you get from decomposing a tree could be unnecessarily complex. In order to avoid this you could prune a tree or a rule set to remove redundant tests or rules. Well what about going from rules to trees? Well this is actually much more difficult. A tree cannot easily express a disjunction between rules despite the opposite being true. Further a given rule base might not have the same sub or superset of attributes required to assemble a representative tree structure. So for example keep in mind that when going from trees to rules all rules would have the root node specified as part of its antecedent. So what we do if this wasn't the case in an initial rule set that we wanted to turn into a tree. At this point we've covered all of the major forms of knowledge representation in AI that are used today. However this is not an entirely exhaustive list. Just a list of the ones that are used most frequently. And here's just a reminder of some of the many knowledge representations we've considered in general so far in this course. Alright so now we're going to shift gears and start talking about expert systems beginning with the what, why, and when. The term expert system can be abbreviated by ES and it can go by a number of names, a knowledge based system, a knowledge based decision support system, an intelligent decision support system, a rule based system, or a production system. Now these names aren't entirely equivalent but when you hear them the first thing you should think of is expert system. Here are some different definitions of expert systems. First we have a computer system that emulates or acts in all respects with the decision making capabilities of a human expert. Here's another, a computer system that operates by applying an inference mechanism to a body of specialist expertise represented in the form of knowledge. Here's a third, a program intended to make reasoned judgments or give assistance in a complex area in which human skills are fallible or scarce. Here's a fourth, an expert system is a program designed to solve problems at a level comparable to that of a human expert in a given domain. And lastly we have expert systems are a system embodying specialist expertise, for example medical knowledge. This diagram is meant to illustrate where expert systems lie with respect to artificial intelligence research as a whole. Here we see expert systems as a subset of all knowledge based systems which is a subset of artificial intelligence programs. You might hear the terms expert systems and knowledge based systems used largely interchangeably. However the distinction is that expert systems tend to focus on knowledge that is considered expert level. The thing that distinguishes knowledge based systems from artificial intelligence programs is that knowledge based systems make domain knowledge and explicit separate resource from the rest of the artificial intelligence system. So in particular expert systems store all of their knowledge and relations in a separate knowledge base and then the reasoning component stands alone as its own separate entity that can work on that knowledge base. This aspect is what distinguishes a knowledge based system from the rest of artificial intelligence work. In this course we'll tend to use the term expert system but you can basically think of them as being synonymous with knowledge based systems for the purposes of this course. Recall from our lecture on the history of artificial intelligence we had this slide describing the dawn of expert systems. We saw the birth of such systems begin in the late 60s and accelerate through the 70s. The earliest systems had a distinct focus on scientific problems including organic chemistry and diagnosis in the medical fields. At a really high level what are some general characteristics of expert systems? Well first and foremost they utilize symbolic reasoning. In other words knowledge must be represented symbolically through things like trees, rules, frames or description logics. Expert systems also apply heuristics to guide the reasoning in attempt to reduce the search area for a solution. Search is an essential aspect underlying how these systems operate. With a goal being defined good or the best solutions we'll be covering search and depth in a later module of this course. Now let's think about expert system characteristics in contrast with other artificial intelligence systems. First expert systems tend to deal with subjects of considerable complexity. Typically they're focused in a narrow specialized domain and they provide expert level solutions to complex problems. So at the end of the day expert systems aren't typically focused on automation or convenience of trivial tasks. As I implied before the knowledge and expert systems is separated from its processing or in other words the inference. This gives us a reusable shell framework for these systems. They can make it easier to plug and play an expert system framework and adapt it to solve entirely new problems. Another thing that's emphasized in expert systems is the need to have high quality performance. The mantra here is that speed doesn't really mean that much if you get a wrong answer. However with that in mind it's still important that our expert systems be as fast as possible. In other words a correct answer doesn't mean much if it comes too late. For example if a patient has already died or a nuclear power plant being controlled by an expert system has exploded. Another commonly important aspect of expert systems is that we want them to be capable of explaining and justifying the solutions they come up with. This is just another way of saying that we care about their interpretability or their understanding ability. And lastly we want them to be flexible. Often expert systems are focused on domains where new information might need to be incorporated or old information might need to be fixed, corrected, or updated. Here's a table that tries to outline some of the major differences between thinking about an expert system versus thinking in traditional computer programs. For example when it comes to control and data, conventional programming implicitly integrates the two while expert systems explicitly separate them as you've just heard. In conventional programming a solution is usually reached using an algorithm while an expert system this comes from inference on rules. Also when it comes to explanation conventional programs usually don't have a mechanism to do this but in expert systems this is usually an important aspect. And lastly looking at modifiability conventional programs are usually difficult to modify while expert systems usually offer a more reasonable easier path. Here is a high level schematic of an expert system. While everything inside this dotted line is part of the expert system itself we have a non expert user who can query the system and get advice back. And we have a knowledge base in the expert system that has been assembled based on the knowledge from expert human beings in the real world. Ultimately the purpose of an expert system is to replace in other words automate or provide support for human experts in solving or advising on real world problems. There are two main components of an expert system, the first being the knowledge base itself. This is the home of symbolically and formally represented knowledge that can take on many representations as we've mentioned. The second key component is the inference engine. This is responsible for reasoning in other words drawn conclusion from the knowledge base. Critically the reasoning or inference approach must pair with the representation being used. So if you have an expert system that was designed to work with rules you couldn't simply replace them with trees or frames without expecting some major issues that might need to be resolved. Or thinking about completely redesigning the expert system from scratch. In addition to those key components there are also some other common components of an expert system. For one, a user interface. This is just a mechanism by which the user and the system can communicate with one another. Another common component of an expert system piece of software is a knowledge base editor. This is also known as a knowledge acquisition facility. This basically provides an automatic way for the user to enter knowledge into the system by passing the need for explicit coding expertise. Basically at the end of the day this makes it easier for non computer science experts to help maintain and prove an update and expert system. And lastly expert systems often have a component of an explanation system. This is also known as a justifier. This component is responsible for explaining the reasoning of an expert system to a user in the form of some natural language. Or something is close to natural language as possible. Here's this schematic I've put together to try and better capture all of the different aspects of a typical expert system. Again on the outside we have a user who can ask queries and get back advice and they're interacting with some user interface. This user interface is importantly connected to the inference engine as well as possibly being connected to a knowledge base editor and an explanation system if they're available in that expert system implementation. Notably all of these items belong to a shell. This is a reusable part of an expert system. From here the inference engine is connected to the knowledge base. This is made up of rules, general facts, questions that might be needed to ask the user. And a temporary memory space for case specific facts or new facts can be added when investigating a specific query from the user. Putting together an expert system isn't a trivial affair. So why do people take the time to develop or use them? Well first off when it comes to human expertise it's often in short supply. There might be only a few experts in the world to begin with or only a few available to work on the task. Such experts can be expensive to develop or to hire. Or they could be simply hard to get ahold of in a hurry. Sometimes even an expert has trouble applying their knowledge quickly, especially in very complex tasks and it may take them some time to apply their knowledge. Further it can be impractical financially to have a human constantly on call to be able to provide their expertise. Beyond this experts can be lost due to retirement leaving their job or death. Implicitly expert systems serve the following functions with respect to expertise when they're developed. They can serve to document or preserve expertise to reproduce or make available that expertise on demand. And they can be used to teach or disseminate expertise that's been stored as part of that expert system. Beyond all of this at the end of the day computers don't get bored, tired, frustrated, or scared. So having distilled human expertise into a computational form avoids some of these issues as well. In terms of their application there are many broad classes of expert systems. They've been designed to handle configuration problems. In other words to assemble proper components of a system in the proper way. They've been applied to diagnosis. In other words to infer underlying problems based on the observed evidence. Also to instruction. Thanks to their justification systems they can provide intelligent teaching so students can ask why, how, or what if questions just as if a human being were teaching. They can also be applied to interpretation problems where we want to explain observed data, monitoring where we want to compare observed data to some expected data and judge performance. Also planning, we want to devise actions to yield some desired outcome, prognosis, or we want to predict the outcome of a situation, for remedy to prescribe treatments for a problem, and finally control where we might want to regulate a process. Further a control system might also require interpretation, diagnosis, monitoring, planning, prognosis, and remedies all achieved by one single system. Here are some examples of some specific areas where expert systems have been used. In medicine we have disease diagnosis, medical alert systems, and healthcare management. In finance we have credit analysis systems, pension fund advisors, automated help desks, market surveillance systems, and business process reengineering systems. In manufacturing we have machine fault diagnosis, robotics, computer configuration, and materials spillage identification. Beyond that we have seen them used in human resources, data processing, and homeland security systems. As a segue into our next lecture we are now going to give a brief introduction to rule-based expert systems. First off we call the rule basics that we have covered in the beginning of this lecture. In particular we have rules given as if then expressions. Rules themselves as a knowledge representation are the most common representation used in expert systems, in particular rules of the if then form. In such systems rule antecedents are only permitted to be conjunctions or ants. The inference engine in rule-based expert systems determines which rule antecedents are satisfied. In other words the left hand side must match a fact in the knowledge base, assuming we are doing forward chaining, as we will see a little bit later. When this happens the right hand side of the rule or the consequent gets activated or fired. This consequent activation can lead to new facts being added to the temporary knowledge base of an expert system. Therefore the activation of one rule may subsequently lead to the activation of other rules downstream once their antecedents are satisfied. For simplicity in this course we are going to focus primarily on rule-based expert systems. So when a rule-based expert system is preferred, we will first off when knowledge is diffuse. In other words there are large number of facts which are more or less independent from one another. They are also preferred when knowledge can easily be separated from its use. In other words there is no dependency on how to use knowledge. For example when we need to decide the ingredients of an item, but not so much when we need to decide how much of each ingredient we need to mix up together for a tasty recipe. Another term that you will hear that is useful to define now is that of production systems. The term production systems comes largely from industry and in these situations the consequence of rules are usually actions. The term production systems is typically associated with the monitoring or controlling of tasks. However I have noticed that there is an inconsistent use of this terminology. On the east coast production systems usually refers to rule-based expert systems that use forward chaining in particular, but on the west coast the term production systems can refer to any kind of rule-based expert system. So for this course we will assume that production systems refer to rule-based expert systems that utilize forward chaining. Production rules can take if then expressions and format them in the following way. So if light is red then stop. Where you put the antecedent on the left side and the consequent on the right. So here is a summary of today's lecture. We started by discussing aspect of rules as a knowledge representation. We talked about antecedents and consequence. The different forms that rules can take and the relations that are used commonly within them. We discussed defaults and exceptions. And at a high level we touched on the basics of inference and matching. We also discussed how trees could be converted to rules and potentially vice versa. Next we introduced expert systems and defined them primarily as an artificial intelligence system designed to solve highly specialized problems require expertise. You are also introduced to some of the basic components of expert systems which will dive into a much greater detail in the next lecture. And lastly we introduced the term rule-based expert systems and noted that they are by far the most common and easiest form of expert system to develop. And lastly introduced the term production systems which will think of in this course as rule-based expert systems that utilize forward-chaining. Here's today's quote. Be warned that being an expert is more than understanding how a system is supposed to work. Expertise is gained by investigating why a system doesn't work. Just a note that assignment three is now available. This assignment will cover knowledge representation, expert systems, and the use of a specific expert system programming language called "Pike". This is likely to be the most challenging of the four homework assignments, so I suggest you dive into it as soon as possible just to make your life easier. Also note that midterm paper summaries will be due soon. Please check the syllabus for the due dates of both of these items. And with that, again thank you for your attention and I'll see you in the next lecture.
