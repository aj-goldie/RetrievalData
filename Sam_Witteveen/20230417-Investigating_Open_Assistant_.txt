
 One of the projects that people have been waiting on for quite a while to come out is the open assistant. And this came out just over the weekend, both models, user interface and data sets. And we're going to look at all of them. So the open assistant is basically a project that was launched by a group of people. I think one of the co-founders is Yannick Kilcher, a very popular Youtuber, and also a number of people from lion and a bunch of people in the open source community have got involved in this project. And the goal was to basically build an open chat GPT style project. And they started this last year. So it's been going for a while. One of the key things that they did was work on building software to be able to collect data from people. They would have people putting in prompts. They would have people pretending to be the AI returning response to the prompt. And they built that up over time, which they've released this past weekend. So let's jump in and have a look at it. And we can see that, okay, they've got a blog post talking about it being released. I'm talking about what's going on with this. I'm not sure that all of the data, etc. has been released. I'll have a look at some of the data as we go. Okay, so the UI that they've released, you can actually use the model online or we can use one of the models online. So the model that you can use online is basically a fine tune llama model. So this is not something that is commercial. They haven't released this model. This is something that you can just use on their site. As I'm looking at this, they may have updated some of the UI as well. But you can see here I've come in and you can basically, it's very similar to chat, you can basically have a conversation with it. So you can click into different chats in here to see here it was a version that I tried on the weekend. Basically asking it who Marcus Aurelius was, asking it a bit about his son. He got some of the facts here were totally wrongs. But it turns out also, I was reluctant to release a video about this straight away because at the start it didn't seem that good with the responses. It turns out that they may have had some of the settings wrong because they've updated some of the settings. They've asked people to change the samples for this. If we look at if we started new chat, you can see here we can actually set the model is the llama 30b one. Supervised fine tuning on the open assistant data set. We see we've top K of 50 top P of 95 and the temperature of 0.9. So they've changed these maybe based on feedback from the community to get better responses. And sure enough, just this evening, it definitely was getting better responses for this. So you can see here I was asking it to give me a list of Roman emperors from the first two centuries. I didn't even get everyone from the first century in there. When I asked it to give me the use that they were emperor, it certainly got this correct, but it stops there. And it does seem to have some knowledge about what went on after this, but not in a great way. But new one seemed to go on a lot further than the two centuries. And when we asked it for dates, it didn't do a great job there. Eventually probing it a number of times. I managed to get it to give me the Roman emperor and the dates. And these look to be all pretty correct in here. So going through the first century and going through the five great emperors. And having come with us because there's a really exciting here. So earlier on, it just seemed to think that he didn't even exist and skipped him up totally. So it's very interesting just to play with the model in there, there you are. And you could jump in straight away and get started with this. You can set the language, they've got a bunch of different languages, which I'll talk about in the data set. So this is pretty cool that the fact that they're supporting different languages in there. And they've got a whole bunch of different things that you can come in here. You can also contribute to labeling data and creating data to make the data set better, which is a key thing that is definitely worth looking at. And this is basically what they've released as a user interface for people to just get started. Now, if you're prepared to jump into some code, you'll see that they've actually released a bunch of things in code. So in code, they've released a number of different models, which we're going to look at one of these in a second. They've also released the actual full data set, which we'll look at in a second. Starting with the model, here's a collab of the open assistant by thea12b. So this one is fully open source, both the model, the base model and the open assistant data set allows you to basically use this, you want straight away. So I've just brought this in, we're bringing in the large one. You will need a decent size GPU to do this. I'm loading it in a bit and we're going through and generating. And it turns out that I'm using the same prompts that I normally use when we've been benchmarking some of these models. So if you've seen some of the other collabs with me going through it, very similar here, asking it about llamas, alpacas and koalas. It's definitely to the point more this model. It seems to be quite good at describing things and getting at least some of the basics. I was quite impressed by the letter that wrote to Sam Altman. It's even down to the things where it has the best regards and your name. So a number of people have pointed out that it's quite good at substituting out names and using things like this, your name as a substitute for privacy in there. That's probably used to liberate on their part in how they've trained the model for this. Simple things like the capital of England gets that right. Writing a story. It also does a decent job at this. Maybe not the best example of this, but it's certainly getting key ideas right and starting to create a story even if the koalas has a very amusing name of Pongo. Asking it, that's also the AI questions of as an AI, do you like the Simpsons? It does quite nicely with this in that it doesn't pretend to be human, which I think is good. I, we get straight up the front. I'm not a human, but I can tell you that the Simpsons is one of my favorite TV shows. So it also doesn't shy away from having an opinion, which definitely gives it a different feeling than the open AI chat, GPT and GPT for models. It goes on to then give us a little bit of information about Homer that we asked. So this is pretty much on point. Lastly, I was playing around with it to get to use some tools and stuff. It seems like this is still not working there. We need some fine tuning in there. So they released a paper along with the actual models, the data set and the user interface. The paper goes through some of the key concepts that they did. I'm going to go to and depth into it. The key thing that I would look at is this data format for the conversation trees. So what they do is they basically have trees where they start off with a prompt and they have multiple answers leading to multiple prompt responses and they're more even more assistant responses. So this shows you that just one conversation tree here has 12 different messages in it. And this is key when we look at their data set that they released. So this is the data set that they released. You can actually load this up and have a play with it. So I was curious to see how they'd done it and how they'd put it together and how they handled these trees. They do actually have tree IDs for this and we can go through and we can actually sort of sort out looking at the data and looking at the number of languages that are in here. So we can see that okay, these are the languages that are actually in here. 25 different languages. So we can actually see the amount of examples for each of these languages that are in here. This is just from the train set from memory. There's roughly we can see that the data set is very heavily English and Spanish and then it drops off quite a lot to Russian, German, Chinese, bit of French and then we don't have a lot in other languages. I think we had one and a half thousand for Thai. Surprisingly, Japanese was actually quite small as well. So we can go through and actually then count the number of trees with this as well. On the whole, it seemed to me that there weren't actually that many of these conversations. If we go back to these kind of trees, I think there is only around 4,000 or so of them for English. So this is something I definitely want to look into a little bit more and see my guess is that they will probably benefit from if they haven't done it already using the Dolly 2 data set of 15,000 different prompts and responses in here to augment this with what they've got in here. If you are a speaker of one of the other languages, I would encourage you to definitely go in there and try and contribute as much as you can. That was one of the things that I saw for certain languages, perhaps like Thai, there's not a lot of Thai data sets out on the web, but it does seem that the community there got behind it and had a lot more answers that a lot of other languages that probably should be much bigger than them. Activating a community around a language and getting behind it seems to be definitely a key thing here. I'm hoping that over time they're going to release a lot more of these data sets or that the data set is going to get a lot bigger over time. Currently at the moment it doesn't seem like there are as many data points as I actually thought there would be with this. So anyway, have a play with the model with the user interface one and with the Pi Thea 12B1. If you wanted to use this in a project you certainly totally can for the Pi Thea model. You can use this for commercial things. I think it's got a very standard license on it. And if you want to use the data set for training and fine-tuning your own models that's something that you could certainly look into try out yourself as well. Anyway, as always if you've got any questions please put them in the comments. If you found this useful please click like and subscribe. I will see you in the next video. [BLANK_AUDIO]
