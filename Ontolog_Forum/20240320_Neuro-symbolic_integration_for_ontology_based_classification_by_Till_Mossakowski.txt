Welcome everyone to the ontology summit, 2024. Today is the 20 March 2024 and we're really excited to have our speaker today, Bill Mosikowski, who is going to be talking on neurosymbolic integration for ontology based classification of structured objects. So I'll turn it over now to our session chair, Ravi, who will introduce our speaker. Ravi. Thank you, Ken. Very kind of you to get us started on this very nice topic. And I'm handling the track a, which is foundations and architectures. And we are so delighted. We had very good start with Gary Marcus and John Sawa and later last week with the Fabian new House. Today we are very excited to have, I would call a colleague of Fabian Fabian and tell Moskowski, who is our professor speaker today. They are at the same place at Otto von Geric University at Magdelburg, Germany. It's in the middle of Germany. I was looking where it was and he has worked a lot on ontology and related subjects such as specification language development called Dol, as well as in development of heterogeneous tool sets. He's a professor of theoretical computer science at this university and he has research interests in logic, knowledge representation, semantics, neurosymbolic integration, as well as applications in energy network simulation models, chemistry. We will hear today about more on chemicals on Gartner hype cycle relating to AI, and on modular design patterns. So I welcome professor till Moskowski to give a presentation and you can kindly share your screen. And please go ahead. Thank you for coming. Yeah, thanks for the invitation and the introduction. I hope you already can see my screen now. So I'm talking about neurosymbolic integration for ontology based classification of structured objects. As Ravi said, this is mainly about chemical entities, but it can be generalized to arbitrary structured objects as well. Here's my overview. First I will speak about the symbolic side and then come to neurosymbolic extension of ontologies. Yes, your slide didn't change. Oh gosh, we are still on the. Now we are on the second slide. Thank you. Yeah, okay. But. Thank you, Fabian, thank you. Thanks for the hint, but I. I should not. Um. Now it is fine. Yeah, yeah. And does it change now? Uh, no, just the slide stays the same. But your cursor is moving. I will switch to the PDF. Sorry for that. No problem. Yes, we can see now it's changing. Yeah. Okay then. Yeah. The third section will be transformers that enhance performance and also interoperability. And then in the fourth section, I switch roles. So then ontologies can help deep learning to improve performance. And then there's an outlook. So symbolic knowledge representation. So there are a lot of ontologies around that provide really high quality knowledge. We have seen this last week from Fabian, and one of these ontologies is Kebby, the ontology of chemical entities of biological interest. Here you see the part of the taxonomy, chemical entity, molecular entity, inorganic and morganic, and so on. And here at the bottom you see caffeine. You probably had this this morning. And here you see the structure formula of this chemical. And very importantly, the structure formula can be represented as a string, which is called the smiles string. We will work with this later. And then of course, a definition in natural language and so on. Now, Kabi is rather small. It's about 60,000 curated entities that are there. Pubchem has about 110 million chemicals in it, but it's not in real ontology, it's more a database. And here GDP 13 even has 1 billion entities. But this is not real chemicals, but only proposals, what could be new chemicals. And the growth of kebi is rather slow, because it's really along the lines that Fabian spoke of last week. So that really expert knowledge is integrated there. There's a consensus among expert reached and so on. So the growth will never reach. So at least in this way, if it's going like this, it will never reach the dimensions of the Pubchem database with hundreds of millions of chemicals. And the problem is that automated text mining is not so helpful to replace curated ontologies. First, we have heard by Fabian that onontologies are a community shared consensus knowledge resource. You have to actively form this consensus. And secondly, also some algorithmic approaches can do some text extraction, but then there are noise and pubcom also. So this is used in pubchem to assign some classes, but there are errors, as you can see here. So this walkhavam is incorrectly classified as inorganic, for example. So here you see Valkavam in more detail. And there is classifier, that's a rule based system that can classify molecules in the chemont ontology, which is much smaller than KB. And then you have to adapt this to KB. Also, the rule set is difficult to maintain and understand 9000 rules. So it's also kind of black box. And also it's not the same as kebi. So there are also different classes and the alignment is not 100% and so on. So you see that also purely symbolic methods of ontology extensions come to their limits here. So therefore we look at neurosymbolic methods. We have seen also this Gartner hype cycle last time, but I want to highlight that. Yeah, you see large language model, generative AI is at the top of the hype, but for the first time in the AI hype cycle, you see also neurosymbolic AI there. So neurosymbolic reasoning and classification integrates kind of neural perception. So if you see this child here, you get at once what's happening here. So this is also called fast or system one thinking in Kahneman's book. And if you see this equation here, you have to think about it. It's not immediately clear what the result is. So it's slow. Yeah. And so it's kind of like intuition and ratio, you combines, we want to combine sub symbolic and symbolic methods, and here you see some characteristics. So the sub symbolic world is fast, data driven, also usable for noisy data, flexible and automatic, and system two, logic based reasoning, knowledge driven, you can abstract better, it's more reliable, you don't have these hallucinations of large language models, and it's also explainable. And we want to integrate both worlds here. And for us here, sub symbolic means neural networks and symbolic means ontologies. Of course, there are many more neurosymbolic integrations. So the research questions are, what are useful neurosymbolic architectures and for knowledge representation that is grounded in some structured objects like chemicals, can we be the purely neural and the purely symbolic baselines? Can we use neural networks to automatically extend ontologies and vice versa? Can ontologies help improving the performance of neural networks? So how can we combine these two worlds, neural and symbolic? So regarding the first direction, can neural networks help with extension of ontology? So we have some chemicals here, want to classify them in Cabi and extend the ontology. So how can we classify a novel molecule? This is important because if you classify a molecule, you can also predict the chemical behavior and also enrich data that you have and drive discovery approaches for new interesting chemicals like cancer treatment on, so on. So we first used various classical machine learning algorithms for ontology extension, and also long short term memory networks, which can actually process strings. That's important because we have this input smile strings. These others have fixed length chemical fingerprints as inputs that are kind of attributes that you can generate from the chemical structure. But here an LSTM, which also was used by Google and Yahoo until 2016 for language translation. Yeah. Can read in this mystring and you have kind of repeated copies of this network reading the individual characters, and then some hidden state is propagated and so on. And you can the network can decide how much of the state is kept and how much new things are added and so on. And then there is the challenge that the ontology is, as a learning problem, is quite unbalanced because most molecules are not in most classes. So we have a lot of zeros there. So we use the subsampling approach that we sample some classes, say 100, 200 or 500, which have a certain number of members, such that these are also disjoint without overlap. And then we here have f one scores, which is a kind of quality criterion, how good the classification works. And you see that all these different machine learning algorithms. And here the LSTM work quite well. Yeah, some of them work not so well here. Naive Bayes, for example. But if we now scale from 100 classes with 100 elements each to 500 classes with 100 elements each, you see that the performance declines. Except for the LSTM, it only declines a bit. So the LSTM approach is most robust to problem sides. So you see that the deep learning approach here can outperform everything else. And also with regard to classifier here, the blue curve is classifier. So this is the path length between the prediction and the asserted parent in the ontology, how many steps you have to take in the taxonomy. And you can see that the LSTM here generally takes fewer steps than classifier. So we can also beat the baseline here, the symbolic baseline. And then here you see some sample ontology extension. So the blue arrows indicate what has been newly added and is correct. The red arrows are things that are added but are not correct. A problem is that the LSTM approach struggles with aromatic ring structures. Like here, naphthionic acid has two such benzene rings. And here you see that if you have a molecule wise average f, one score, you see that there is a good portion close to one, but there's also quite a portion close to zero, which means there's no useful classification. And this, we have seen that this is, for example, for these ring structures. And these rings cannot be very well detected. And therefore, we have used transformers. So transformers revolutionized deep learning in 2017. And they are also used for language translation, for large language models are based on transformers. And, yeah, in various areas you have now transformers and 2017, there was really a kind of big switch. Everyone switched to transformers. And so they have an encoder and a decoder, and they have the multi hat attention. So that means. Yeah, it's kind of this. V is for value, key is for key, and q for query. So you have some query that is learned and then you have key value pairs and you try to match the query with a key and retrieve the value. And this gives you an attention relation. And via this attention, you retrieve some values. So it's kind of borrowed from information retrieval. And with this, for example, in transformer language models, you can, in a sentence you can say, for example, the down tends to sit, so it kind of belongs to sits and also the place attends to he. So also a bit more distant attentions are possible. Now, we based our work on Bert, Roberta and Elektra. These are bidirectional attention models, so you can attend in both directions. Also you have a pre training phase and a fine tuning phase. And in case of Elektra, the pre training phase is based on a masking. So you have a smile string here, you mask certain things and then a generator generates something that replaces the masked items. And then you have a discriminator, which is basically electra, that should detect whether this was the original or something that is replaced. Yeah, so that's the pre training phase. So with this pre training phase, in case of language models, you learn kind of language. In case of our application, you learn smile strings, how they are structured and so on. And then you can fine tune with the task at hand, which here is classification in the cabbie ontology. And this interesting thing is here you see the attention relation at various layers. At layer two, it's not very interesting. You mainly attend to the next character in this milestring or to the previous one. But in layer five, a bit later, you attend two whole structures, like here, the two benzene rings, or here, these oxygens around the sulfur atom. So this kind of, is some kind of explainability, how the classification was done. And actually these Robertia and Elektra models, this was done by Adele Memoryani, who is also in the audience. So he's in my group. And this actually could beat the LSTM approach, both at the molecule level f one score, as well as the class level f one score. And so we have also tried a newer cabbie version. So where over the time, using manual curation and discussion among the experts, new items have been added to the ontology. And we see that with this new version of chemi, we could improve the classification results. So that means our approach kind of gets better with the ontology. So if the ontology gets better, then we can kind of take up this expert knowledge represented in the ontology and directly use it for classification. There's also a tool online called cavifier where you can enter smile strings and then get some predictor classes. Here you see the URL where you can try this. And also the framework behind that. We have a research project. Lottie, who is also in the audience, is working there in the swiss side and in the german side, Simon, where we take a molecular graph and embed this into a vector space. Have then the transformer approach. And then we have a third level called logical neural networks. This is a new type of neural network that kind of sees individual neurons simultaneously as logic gates, like and or not. And with this, we can compute a loss function, a semantic loss function. So we can say in our ontology, we have certain subclass relationships and disjointnesses. Then we can compute whether our classification adheres to that. So it could, for example, violate a disjointness if it classifies a molecule as both a and b, although a and b are disjoint. If this is the case, then there's a penalty via the loss function, pushing the neural network at the second level here to not learn this in this direction, but to change the weights of the network and to learn something else. And also we want to extract relations in this graph, say, for example, part of relations or functional groups and things like that. That biological functions. And these relations can also be axiomatized in cabbie. And this is in owl ontology, that you can have existential restriction. For example, a certain molecule has methyl group. And then you can check whether these relations are present when they should be. And if not, then you can also express via a loss function. This shouldn't be the case. And push the network to avoid this error. Okay, now the other way around. Ontology pre training. How can this improve neural network performance? We have used the Tox 21 data challenge, which contains about six or 7000 chemicals and twelve different kinds of toxicity. And this is a hard task, because chemicals can act with biological organisms in very many different ways. And toxicity can have many reasons. And our question would be, can ontology knowledge improve the predictive quality of neural networks? And the ontology can provide important features and distinctions. For example, very simple, organic versus inorganic would be an ontology distinction. And if we use pre training with ontology, we can kind of make the neural network to learn this distinction independently of the data that is later used. And then the network has a certain prior, a certain kind of prejudice, if you wish, that in this case helps. So here is the architecture in a certain architectural pattern language. For neurosymbolic integration. You take pubchem chemicals. Remember, we have 100 million of them. Use them for pre training of the electron models. So you can have here you have an electra model that then knows about smile strings and chemicals. Then we use the cabbie ontology for pre training. We have a pre trained electra model which is pre trained also with ontology, not only with pubchem. And then we use fine tuning with the tox 21 data set, and have a fine tuned model which now can infer toxicity of new unseen molecules. And here on the left hand side, you have the same pipeline, but without the ontology pre training. Now, the result is this. With ontology pre training, we have better results, as you can see by the blue curves here, than without. And we can also show that this outperformed the state of the art in this tocs 21 challenge. The interesting thing is also the ontology pre training can also improve the interpretability of attention weights. So here you see the attention weights without ontology pre training. So here you see something, and here you see some structure, but everything else is quite blurry and unstructured. And here with ontology pre training, you see that there is much more focused attention. So here you focus on parts of the smile string. So here this from top to bottom, this is the smile strings as input. And here you see that another is some entity, some character in the smile string attends to parts of the smile string. So two parts of the molecule. So these neurosymbolic design patterns that I have used two slides ago, they belong to a general pattern language designed by Beckham and also Frank van Hamelin is there. They have designed this. That's interesting. So you can. For this. Yeah. With this notation you can formulate neurosymbolic design patterns. There's also an ontology behind these pattern elements. And then you can use doll. That's now my work based on becom et al. I have provided a notion of refinement on combination using the distributed ontology language, where you can take such patterns, like we have seen this here, this is from the previous slide, and build this in a modular way, like here, you combine a certain training of a certain model with inference in a semantic model. And here you have training and inference in one big box here. So that would be the general hope that via such patterns, you can design neurosymbolic architectures like I've shown you today, in a better and modular and more reusable way. Now the conclusion. So, we have shown that neural networks can extend ontologies of chemicals, but the hope is also other structured objects, as long as the classes and individuals are annotated with certain graphs or other structured objects, then we could use the same methods. From neural, you can go to symbolic, to extend the symbolic world, in this case the ontology world. And on the other hand, we can also see that ontology pre training can improve the performance of transformer networks. So the symbolic knowledge, so in this case, high quality ontological background knowledge, can also improve the performance of neural networks. Also, we have shown that we can beat the baselines that are either purely symbolic or purely neural. And we have taken a very short glimpse on these design patterns. And as one option of future work, there would be novel neural embeddings for ontologies. Again, Adele is working on this. Again, anything that I have presented today was done by my group, so it's not my work alone. I only have a small part in it. My group is really excellent, and Adele is actually working currently on box embeddings. That means you embed items into n dimensional spaCe. I think he has 16 dimensions working best. But here's a projection on three dimensional space, and Here you see a certain chemical. Yeah, chemical entity. That's a class, that's a very big cube containing everything else. And kind of containment, geometric containment is meant to be class inclusion. So this is also a very explainable representations, because you can kind of directly look at your ontology classes. Yeah. Thank you for your attention. And there's room for questions. Yes, thank you. Till a very, very enlightening talk and fantastic coverage of a very difficult and wide subject, especially chemicals being one of the toughest symbolic language. It's the chemistry, especially organic, being very difficult subject to tackle. I will hold my questions, I have some in the chat, but I will first request todd to kindly go ahead. And then John Sova. Thank you. Hi, tayl. This is fascinating work. I sort of ASked this question of Dev MacPherson last July, and she was not aware of any work in this area. And based on the times of these publications you have, I don't understand why. But in any case, to the first bullet point you have on the conclusion, you briefly explained or suggested what a structured object is, could you expand on that? What is a structured object? Yeah, that's a good question. So actually, that's future work, to see how this can be extended to other structured objects. And so here you see, the chemicals are graphs. So I would say if your ontology is an ontology of graphs, yeah. So your classes or individuals are associated with graphs, so annotated with graphs, then it should work. We hope to have to extend this, for example, to proteins, which are also chemicals, but also to biological pathways, for example. And it's unclear how far this works, but till, are there any, you know, when you say a graph, that's just a set with some relation binary relations on it, and the bi, the binary relations may be non transitive, or transitive and irreflexive and so on. So when you talk about structure, and, you know, the chemicals have a certain relation between their elements and those relations, those binary relations have certain properties, you know, as I said, transitivity, reflexivity, symmetry, so on, is there a way that you can qualify what those binary relations must be in order to meet your criteria of structured, or a structured object? I would say if you have a binary relation at all, then this is already fantastic, then there is a great chance that this approach will work. But there are of course many ontologies where you don't have such graphs or such binary relations associated to your classes. Well, I would suggest then that those things are not sufficiently well constructed or defined. And in the case of using owl for your ontology, then the particular relations are, would be called object properties, correct? Not data properties. No, no, that's so caffeine, for example, has object properties in the old sense. You for example, have an oxygen part here or a methyl part here. So there are certain Hesper relations. Yeah, but that's different, that's related to, but different from the graph that is, as a whole. This graph is not a graph of object properties in the ontology, but this is a graph that as a whole is attached to a single class. And this is quite unusual in ontologies, I would say. So this suggests that this notion of structure is a meta level structure. That is, it's a collection of object properties that have relations among themselves. I mean, you could, you can try to. Now, I would say it's completely, in the first place, it's completely unrelated to object properties. Imagine you have a taxonomy, and each class in the toxonomy has an annotation property, and this annotation property contains a graph. That's what you should imagine. Thank you. Of course, once you. Yes, okay, that's what we have here. That's what we have here. Okay. That said, of course, if you have that from that you can reconstruct object properties like part of, and can say, okay, yeah, I have certain part of relations between different graphs and so on. On the other hand, if you have object properties in your ontology, you could also say you have individuals there that come with family trees, and the family trees are kind of contained in the ontology via object properties. Then, of course, you could extract from these family trees in the ontology, you could extract these graphs and annotate them directly as annotation properties at the individuals. And then you have kind of structured objects that are generated from the ontology. So you could have some kind of relation to the object properties. But as we do it here, it's in the first place, completely unrelated to object properties. Thank you. Okay, thank you. That's an interesting explanation. John, can you unmute or speak? Okay, I had several questions, and one is that there are some constraints that are absolute. For example, when you're doing various kinds of reasoning, especially in practical applications, you have a database where, which is absolute certainty. I mean, of course there may be errors, but it's assumed to be absolutely correct. For example, in banking and finance, the database of what people have on hand on their files, in their investments is absolute certainty. And no errors are permissible. None. And the question is, how do you combine the reasoning methods of abduction, deduction and induction? These neural networks are excellent for abduction, but they always have to be tested by a very precise deduction to make sure that they're correct in comparison to your database and to an ontology that is also very precise. So, for example, in banking, there are certain very vague kinds of ontologies that are shared by all banks. However, every individual bank has very, very precise constraints on how each of their services are structured. And you must have absolute certainty that whatever comes, messages come in or go out, must be absolutely consistent. And just a 99% accuracy is intolerable. You must have accuracy down to the fraction of a cent. And how do you support that? Yeah, so you see here at the upper left level, you see the ontology and its axioms. And we also do deduction here in the classical sense. So we kind of deductively close the axioms of the ontology using an our reasoner. And Simon is also experimenting with first order logic here to characterize chemical classes in a more expressive language. And then he also uses deduction to see whether this is consistent, for example, with the classifications that we have. So here at this corner, or at this kind of blue area, we have classical semantics based on two valued logic, and we have deduction. Now we have this transformer network here, or here we have a graph neural network, perhaps. So this is kind of deep learning. And this is basically induction. From examples that are labeled with certain classes, you learn a general method, how to classify. So this is kind of pure induction. And now the interesting thing is that the logical loss function now kind of serves as a bridge between deduction and induction. And the logical neural networks are also such that you can place. You have a fuzzy logic, so you have logical truth values between zero and one, and you have upper and lower bounds. And so, for example, in the ontology, you could say everything has upper bound one and lower bound one. That means absolute certainty. But maybe you have parts of the ontology that are not so sure. So you could have a lower bound of 0.7 or whatever. Yeah, if you want to specify that. And then within sub formulas here, you propagate kind of these bounds and can also lead. This can lead to other bounds, and this can even lead to the phenomenon that the lower bound is higher than the upper bound, which is kind of a sign for inconsistency, or at least a certain degree of inconsistency that you have here. And this is then fed into the loss function. And this influences the induction, which is happening here at the lower left side. And the induction then is kind of pushed in a way to learn from the examples in a way that is consistent with this logical axiomatization in the ontology concerning abduction might be that Siemens also finds new descriptions of classes, because this cabia ontology is not always correct. We also found bugs there, and sometimes also it's under axiomatized. So we might also speculate some new descriptions of classes from examples. This could be done with abduction, but that's kind of speculative now. Yeah. Thank you. Fabian has his hand up. Okay, I think that's very good. But one point I'd make about graphs is that every linear language can be expressed as a graph, and every graphic language, for example, organic chemistry, all the elements and compounds of organic chemistry can be expressed in a linear notation. Now, that linear notation is horribly unreadable by humans, and they're actually rather complicated, even for computers. But so the point is that there is no sharp distinction between a graph and a linear language. They are, in some sense, you can map anything one way or another. And some algorithms are better for the graphical, some algorithms are maybe better for the linear. And it's essential to have at some point, the option of having levels of certainty, so that you can say that your ontology may be as good as it you have made it, but there are always possibilities for errors. So you must also always be aware that that's possible, but that you can have constraints at different levels. And all of these things are important. And it's essential, when you're designing a system, to be able to have all these different levels. And I'm very concerned about applications in which they make the large language model things primary. I mean, they're very important for communication to and from humans in a natural language. But when you're getting down to the details of reasoning, you can't rely on them. And they emphasis on the neural networks as primary is just a major mistake because they are very, very important, but they're not the whole thing. Yeah, but John remarked that we have beaten the symbolic baselines here. Yeah, so where is the. Yeah, yeah. So classifier is a rule based system that was used, or still is used for the extension of cabbie. And we here, even with the LSTM, leave alone with the transformer, the electra model that we have developed later, we can beat this baseline. So we are better, we are more precise than the symbolic baseline. So I would not say that symbolic rules are kind of always correct. They also contain errors. And. Yeah, so sometimes, as we can see here, neural networks can beat these baselines. Yes, that's certainly true that nothing is perfect. On the other hand, there are, you can have levels of reliability that there are certain things that, for example, every operating system in the world has updates periodically because that completely change the foundation. However, there is a base version that is absolutely certain and those parts must be absolutely correct. There are other areas where we can tolerate varying levels of reliability. And the banking example is a case where the translations, messages passing to and from internationally are sufficiently accurate that they can be considered correct for the data that they're transforming. But the representation of that data inside each individual bank is totally different. And so that there must be these transformations which some cases they're absolutely correct. Some cases there are approximations. And so you always have the option, you always need the option of going back and asking a question that people, when they're conversing, are constantly making mistakes and interpreting each other, but they always have the option of asking a question until they get to a level where they're sufficiently satisfied that the communication is okay. John. Yeah, but John, here we don't have the necessity or the possibility to have a reliability as in a bank. So that's for sure. So we are not working in this kind of league here. And one answer to your question between, or to your remark, strings and graphs are the same. Of course we have the smiles. Strings that can be converted into graphs and graphs can be converted into smile strings. That's true. But the important thing is here that we have isomorphism classes of graphs. Yeah. So it's not important how this graph is drawn in the plane here. There are very many ways. Also the smile strings, there are many smile strings for the same graph, and we are interested in the isomorphism class, and that's why we also want to work, or Simon has already done this to work with graph neural networks, because graph neural networks only work on the isomorphism class of the graph, whereas the smile strings can kind of use the particular representation of that graph and learn things about the representation that are not meant to be learned, because it's not about the isomorphism class. And that's the important thing here about structured objects. Thank you. Thank you, till, for pointing out that this is not a banking, but is a chemical kind of application, and that kind of accuracy is not being sought after. But you answered lot of John's questions. I want to give a. I use that. Are you thinking it's just one example? But the point is that there's a huge number of cases in. But Fabian is waiting for a long time, so kindly ask you. Thank you, Ravi. I just wanted to go back to Todd's question, so what's the limitation? And I think sometimes the details are distracting. So I think I try, I will, I will try to give a different answer than till, which is less detailed, but maybe makes it easier and gives a better overview. So when Til says we are talking about structured objects, what is really what we are looking? The problem is a classification problem. You get a new chemical structure. New chemical. And we try to classify it in cabbie. Right. And say, where does it fit? And so the, the input we get is what we consider is a structure. You can represent it as a graph, a string. It doesn't really matter. It's. But what is important is that we know something about the building blocks of the chemical, and we also have a do a classification where the internal structure of the chemical is important for the classification. So you can look at the structure of the chemical and say it's an acid or not. And that's kind of the limit. If you would try to predict something like, can you order it on Amazon? That's probably not something we could predict with this approach, because just by looking at the structure of the chemical, you most likely can't judge whether you can order it on the Amazon or not. So one limitation is the annotation. The structural annotation that you get needs to be kind of relevant for the classification problem you have. So toxicity is something where we would probably also say that there's some connection between the internal structure of the chemical toxicity. That's why that kind of works. As I said, many other properties, you probably can't easily predict that way. So what's the, is it only related to chemicals or proteins? No, not necessarily. If you had some other annotation which gives you information about an entity, and it can be a fingerprint, it can be anything, it doesn't need to be graph. As long as you have an annotation which gives you some relevant information about that entity in connection to the classification problem you have. The same approach should work. I say it should, because we so far looked at chemical data sets. We know that it works there. But my guess is it can be generalized to basically any other application where you, again, you have an annotations of the entities that you want to classify. And the information that is in the annotation is kind of related to the classification task you have. Mike Koenigar has a point to make. Mike. No, I was just commenting on this discussion about graphical structures. I mean, I think the point is that the like, and in the case of owl, you can't really axematize it. But till referred to a molecular graph. And so work we did back in 2016, Carmen Hsu had the molecular structure ontology, where we had a set of first order axioms, and the models of these axioms were isomorphic to graphs as mathematical structures. I think that's the kind of structure that till's referring to, is that it's the underlying models that have that structure. And so, for example, one of the things that you can do, in a, say, in a naive way, is you can represent the molecule as a graph in which the atoms, or the vertices and the edges are the edge of the bonds. But what you have to do is recognize that next level of structure where there are rings and chains, bridges, like a variety of these kinds of structures. And that's what's kind of difficult for some ontologies, particularly if you're not using first order to be able to represent. And what we ended up doing was using classes of tripartite and quadriparthe incidence structures, which generalize geometry in order to represent those higher levels of structure. So that might be something else to consider, I suppose, like moving beyond graphs of structures to looking at these generalizations in terms of incidents. Yeah, but Michael, please note that these graphs are not the models of the ontology. They are contained in annotation properties. Ah, well, what if we looked at those as being models, right? What if we looked at them as being. We're learning that that's the underlying structure that we need to learn, because the axioms of ontology should be satisfied by them. Yeah. But then we have a two level ontology here. Yeah. Because each class in Kebi is annotated with such a graph structure. So per class, we have one graph. And the graph, if you construe this as a model of an ontology, that would mean per class in orchid ontology, you have another ontology. Well, no, no, it's not the model of ontology. No, no. The idea would be that each molecule has a definition. Yeah. Caffeine would have. Would be defined by a first order formula. So something is in essence of caffeine if it only if it satisfies the formula. Right. And that definition is a particular graph. I agree. Right. You're right. Each chemical corresponds to that graph. Exactly. That's what Simon was also doing using first order logic. Or he also wants to express paths of arbitrary length. And then you need monadic second order logic, which is, well, kind of natural. Yeah. You don't actually need monadic second order logic to capture the paths or transitive closure, at least something like that. And so that's true. So we have kind of, we are experimented, experimenting with first order formulas or first order plus x formulas that capture these classes. But the problem is, for these 60,000 classes of kabi, to get all these axioms is really difficult. Well, we actually wrote some code that can translate what's called a mol file. Mol file into the first order formula. Okay, that's interesting. But of course, in this first order approach, that's the other kind of aspect in this idea of incidence structures, paths and cycles in the graph correspond to chains and rings in the chemical structure. I mean, those are actually entities. Those are reified entities. So you're not necessarily coming up with all paths in the graph. You're simply identifying that a particular sort of structure, like a chain or ring, benzene ring, for example, is a cycle. Right. Or is a path. You're not trying to find all paths. So that's the other aspect here that's reifying that next level of structure. I know others have made comments such as Phil, but I do have a couple of comments of my own. I enjoyed the fact that the symbol here could be as complex as a chemical molecule or complex chemical molecules combination. And one of the attributes that comes to mind is the stability of the molecule. Does that attribute figure anywhere in your learning to take into account transient or intermediate products of chemical reaction? No, we have not looked at this, but this would, of course, be interesting future work so chemical reactions, I think there are also ontologies of chemical reactions and. Yeah, also other things like solubility of chemicals. So all kinds of interactions of chemicals. That would be very interesting. Another quick question to you is I found that your learning and success rates improved with not only neural inputs into the learning set or training set, but also with little bit of AI thrown in. Whether it was the case of transformers or not, I don't remember. But if look at the graph that you discussed with John Soa in that graph, your improvements were better if you used AI techniques. Yes, indeed. Yeah. Okay. And lastly, something more about patterns, where you are taking them. So you mean the design patterns for neurosymbolic integration, design to implementation. And of course I would like later if, if at all, an opportunity to deal with questions about multi dimension video colleague, but that we can do on email because we know we have run out of time. But kindly do tell me about the implementation patterns using these design patterns. Yeah, I can do that, sure. Multidimensionality. One quick question is, is it related to attributes like tuples in a formula or a function, or is it deeper than that? So is what the dimension, the dimension in multi dimension study, the dimension is defined by one variable, or is it a true space time multidimensional space? So what we have here is the latent space. So yeah, the transformer, or even the embedding, the graph neural network embeds the neural net, the graph of the chemical entity, into some vector space. Yeah, but this vector space is latin space, so it's not interpretable per se. So we don't know what the dimensions mean. So the interpretability is not via the dimensions of the vector space, but via the attention structure of the transformer. And then there's a question whether, for example, this attention structure reveals any kinds of features or structural properties of the graph. That would be interesting to know. So that's also future work. So far we have only seen that it kind of makes sense, this kind of attention, that if you classify something as a certain acid, say, then yes, I think there's naphthionic acid, then you need these benzene rings and you need this part here. But we don't have a systematic analysis of the attention structure and its relation to graph properties. But that would be very interesting. Yeah, but that's kind of future work. So in this strontex project, we have a work package for that. So to kind of, in this project, we want to improve explainability, and we have several ideas there, and that that would also be an interesting idea. Thank you so much. Thank you. John always talks of explainability as being one of the litmus tests of doing good logic, good ontology. So thank you so much. It's been a great talk. And anybody else want to say something, I really want to thank and I think it opened the interaction among you all researchers, opened some collaboration opportunities in this session. I hope you all collaborate to improve or go further in research. Thank you. I hand it over to you. Ken, are you there? Oh, yes. Okay. Thank you. It was a great talk, in my opinion, and. Oh, yeah. And very lively discussion. Now, what, what I'd like to do now is to I invite everyone to come next week when I believe our speaker is going to be Amit Sheth. Although, Ravi, you may have more current information about that. The last I knew is that Ram is going to contact Amit and get the topic and the bio put in on the chat on the web page session webpage. So, tentatively, yes, it is Amit Sheikh and he's going to talk to us. Great. So I hope everyone will then will attend next week and with that, I will adjourn this meeting. Thank you. Thanks for everyone for coming. Thanks especially to till and Fabian. Yeah, thanks for the invitation. Hi, everyone.